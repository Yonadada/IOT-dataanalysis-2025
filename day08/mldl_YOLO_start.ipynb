{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36853eb",
   "metadata": {},
   "source": [
    "## YOLO\n",
    "\n",
    "### PyTorch ê¸°ë°˜ ë¬¼ì²´ì¸ì‹ ëª¨ë¸\n",
    "- CNN, rCNN(Regions with CNN)\n",
    "- https://github.com/ultralytics/ultralytics ì°¸ì¡°\n",
    "\n",
    "#### YOLOv5 ì´ìƒ ì„¤ì¹˜\n",
    "```shell\n",
    "> pip install ultralytics\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b716e861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (8.3.109)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (1.24.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (0.21.0+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# YOLO ì„¤ì¹˜\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5392396",
   "metadata": {},
   "source": [
    "#### ì½˜ì†”ì—ì„œ ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d74eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.109 ðŸš€ Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Source\\IOT-dataanalysis-2025\\day08\\bus.jpg: 640x480 4 persons, 1 bus, 31.5ms\n",
      "Speed: 2.3ms preprocess, 31.5ms inference, 73.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mc:\\Source\\IOT-dataanalysis-2025\\runs\\detect\\predict2\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "# ì½˜ì†”ì—ì„œ ì˜ˆì¸¡\n",
    "## yolo11n.pt - pretrained yolo model\n",
    "## ìžë™ìœ¼ë¡œ yolo11n.pt ë‹¤ìš´ë¡œë“œ\n",
    "## ì›¹ URLì— ìžˆëŠ” ì´ë¯¸ì§€ë„ ì˜ˆì¸¡ ê°€ëŠ¥\n",
    "\n",
    "!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb90c9",
   "metadata": {},
   "source": [
    "#### íŒŒì´ì¬ìœ¼ë¡œ ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35088061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO ëª¨ë“ˆ ë¡œë“œ\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b085562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO í´ëž˜ìŠ¤ê°€ ë“¤ì–´ì˜¤ëŠ” ëª¨ë¸ì˜ ë²„ì „ì— ë”°ë¼ ì•Œì•„ì„œ YOLO ì˜ˆì¸¡ëª¨ë¸ ê°ì²´ ìƒì„±\n",
    "model = YOLO('./yolo11n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89513b23",
   "metadata": {},
   "source": [
    "##### coco8.yaml\n",
    "- https://github.com/ultralytics/assets/releases/download/v0.0.0/coco8.zip\n",
    "- ìœ„ ë‚´ìš©ëŒ€ë¡œ í›ˆë ¨ì„ ì‹œí‚¨ ê²°ê³¼ -> yolo11n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a080e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.109  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=./yolo11n.pt, data=./coco8.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=c:\\Source\\IOT-dataanalysis-2025\\runs\\detect\\train2\n",
      "WARNING:tensorflow:From c:\\Source\\IOT-dataanalysis-2025\\mlvenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir c:\\Source\\IOT-dataanalysis-2025\\runs\\detect\\train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1650 GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Source\\datasets\\coco8\\labels\\train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Source\\datasets\\coco8\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Source\\IOT-dataanalysis-2025\\runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Source\\IOT-dataanalysis-2025\\runs\\detect\\train2\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      1.21G      1.096      2.751      1.478         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.566       0.85      0.849      0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      1.24G      1.165      2.778      1.475         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.557       0.85      0.887       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      1.25G       1.09      2.487      1.215         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.558       0.85       0.85      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      1.25G       1.17      2.767      1.486         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.55       0.85      0.857      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      1.25G      1.198      2.397      1.608         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.546       0.85      0.859      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      1.25G     0.8209      1.833      1.141         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.551       0.86      0.858      0.614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      1.25G      1.403      2.689      1.757         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.544      0.867      0.861      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      1.26G      1.232       3.77      1.674         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.548      0.875      0.898      0.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      1.27G     0.8251      2.752      1.235         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.552      0.867      0.896      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      1.27G      1.026       2.03       1.26         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.64      0.949      0.912      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      1.27G      1.163      2.127      1.546         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.619       0.95      0.912      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      1.27G     0.9907      2.175      1.359         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.63       0.95      0.911      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      1.29G      1.337      3.035      1.778         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.639       0.95      0.911      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100       1.3G     0.8126      2.417      1.239         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.649       0.95      0.912      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      1.32G      1.241      2.917       1.51         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.65      0.783      0.913      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      1.32G      1.177       1.95      1.495         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.655      0.783      0.912      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      1.32G     0.8299      1.498      1.188         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.651      0.783      0.912      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      1.32G     0.5945      1.247     0.9769         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.651      0.783      0.912      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      1.34G      0.698      1.476      1.034         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.651      0.783       0.91      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      1.35G      1.165      1.747      1.338         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.651      0.783       0.91      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      1.36G     0.7612      1.725      1.175         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.652      0.783      0.909      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      1.36G      1.055      1.676      1.233         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.652      0.783      0.909      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      1.37G     0.8997       1.61      1.335         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.818       0.65      0.855      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      1.37G     0.9084      1.589      1.218         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.818       0.65      0.855      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      1.37G     0.6662      1.979      1.074         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.819       0.65      0.855      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      1.37G     0.8673      1.278      1.184         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.819       0.65      0.855      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      1.37G      0.955      1.442      1.412         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.83       0.65      0.855        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      1.37G     0.9466      1.199      1.229         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.83       0.65      0.855        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      1.37G     0.9721      1.674      1.296         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.825       0.65      0.855        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      1.37G      1.005      1.222      1.292         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.825       0.65      0.855        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      1.37G      1.001      1.594      1.329         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17        0.8       0.65      0.852      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      1.37G     0.6603      1.491      1.298         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17        0.8       0.65      0.852      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      1.37G      1.058      1.904      1.341         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.794       0.65      0.852      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      1.37G      1.023      1.903      1.417         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.794       0.65      0.852      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      1.37G     0.9243      1.206      1.313         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.773       0.65      0.848      0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      1.37G       1.01      1.422      1.368         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.773       0.65      0.848      0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      1.37G     0.9942      1.043      1.351         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.81      0.649      0.845      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      1.37G     0.5804     0.8527     0.9593         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.81      0.649      0.845      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      1.37G      0.722     0.7696       1.17         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.792      0.639      0.845      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      1.37G     0.7655       1.02      1.161         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.792      0.639      0.845      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      1.37G     0.7731      1.108      1.116         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.762       0.65      0.845       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      1.37G     0.9341      1.122      1.198         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.762       0.65      0.845       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      1.37G     0.9725     0.9894      1.446         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.728       0.65      0.846      0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      1.37G     0.6764     0.8981      1.089         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.728       0.65      0.846      0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      1.37G     0.6657      1.403      1.085         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.724       0.65      0.763      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      1.37G     0.8526     0.9995      1.252         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.724       0.65      0.763      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      1.37G     0.8618      0.754      1.253         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.735       0.65      0.708      0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      1.37G     0.7657     0.9992      1.139         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.735       0.65      0.708      0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      1.37G      1.021      1.111      1.383         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.731       0.65      0.708      0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      1.37G     0.6688     0.8849      1.103         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.731       0.65      0.708      0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      1.37G     0.7224     0.9239      1.215         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.722       0.65      0.694      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      1.37G     0.8047      1.641      1.174         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.722       0.65      0.694      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      1.37G     0.5522     0.8894      1.019         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.722       0.65      0.694      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      1.37G     0.7379     0.9824      1.114         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.779      0.654      0.686      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      1.37G      0.661      1.121      1.153         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.779      0.654      0.686      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      1.37G     0.7079     0.8469      1.259         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.779      0.654      0.686      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      1.37G     0.6972     0.7099      1.196         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.779      0.659      0.689      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      1.37G     0.7553      1.042      1.196         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.779      0.659      0.689      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      1.37G      0.711     0.7283      1.234         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.779      0.659      0.689      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      1.37G      0.754     0.9504      1.281         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.78      0.483      0.693      0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      1.37G     0.6128     0.6921      1.056         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.78      0.483      0.693      0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      1.37G     0.7732     0.8924      1.298         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.78      0.483      0.693      0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      1.37G     0.6842     0.8159      1.163         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.787      0.483      0.569      0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      1.37G     0.8139     0.7933      1.084         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.787      0.483      0.569      0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      1.37G     0.6066     0.6824      1.036         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.787      0.483      0.569      0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      1.37G     0.9227      1.978      1.319         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.773      0.483      0.556      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      1.37G     0.7674     0.8914      1.177         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.773      0.483      0.556      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      1.37G     0.6574     0.7655      1.044         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.773      0.483      0.556      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      1.37G     0.7011     0.6748      1.273         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.777      0.483      0.555      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      1.37G     0.9602      1.058      1.384          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.777      0.483      0.555      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      1.37G     0.6677     0.7002      1.151         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.777      0.483      0.555      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      1.37G     0.6271      1.009      1.157         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.819      0.483      0.577      0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      1.37G     0.6002     0.5791      1.146         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.819      0.483      0.577      0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      1.37G      1.046       1.83      1.475         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.819      0.483      0.577      0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      1.37G     0.9727     0.9144      1.253         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.789      0.483      0.538      0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      1.37G     0.9009     0.8666      1.335         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.789      0.483      0.538      0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      1.37G     0.6599     0.6286      1.033         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.789      0.483      0.538      0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      1.37G     0.6745      1.001       1.13         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.82      0.483      0.552      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      1.37G     0.8278      1.372      1.303         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.82      0.483      0.552      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      1.37G     0.6305     0.5827      1.126         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.82      0.483      0.552      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      1.37G     0.7831     0.8235      1.103         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.828      0.483      0.549      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      1.37G     0.4473     0.4499      0.941         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.828      0.483      0.549      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      1.37G     0.6889     0.7378      1.036         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.828      0.483      0.549      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      1.37G     0.8111      1.383      1.256         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.467      0.551      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      1.37G     0.6052     0.7461      1.162         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.467      0.551      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      1.37G      0.609     0.8075       1.14         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.467      0.551      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      1.37G     0.5786     0.6391      1.084         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.467      0.551      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      1.37G     0.7034     0.9453      1.098         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.79      0.462      0.523      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      1.37G     0.6647     0.7961      1.161         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.79      0.462      0.523      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      1.37G     0.7881     0.6772        1.1         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.79      0.462      0.523      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      1.37G     0.5717     0.4934       1.06         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.79      0.462      0.523      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      1.37G      0.457     0.4827     0.8521         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.795      0.483      0.521      0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      1.37G     0.4673     0.4813     0.9558         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.795      0.483      0.521      0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      1.37G     0.5788     0.6024      1.099         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.795      0.483      0.521      0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      1.37G     0.5741     0.6223      1.082         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.795      0.483      0.521      0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      1.37G     0.8682     0.7541      1.217         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.825      0.465      0.531      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      1.37G     0.5351     0.4564     0.9039         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.825      0.465      0.531      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      1.37G     0.5242     0.5911      1.006         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.825      0.465      0.531      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      1.37G     0.5566      0.508      1.012         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.825      0.465      0.531      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      1.37G     0.4482     0.4146     0.9347         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.831      0.464      0.557       0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from c:\\Source\\IOT-dataanalysis-2025\\runs\\detect\\train2\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from c:\\Source\\IOT-dataanalysis-2025\\runs\\detect\\train2\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating c:\\Source\\IOT-dataanalysis-2025\\runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.109  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.649      0.783      0.913      0.652\n",
      "                person          3         10      0.623        0.7       0.67      0.328\n",
      "                   dog          1          1      0.527          1      0.995      0.796\n",
      "                 horse          1          2      0.642          1      0.995      0.676\n",
      "              elephant          1          2      0.551          1      0.828      0.323\n",
      "              umbrella          1          1      0.551          1      0.995      0.895\n",
      "          potted plant          1          1          1          0      0.995      0.895\n",
      "Speed: 0.4ms preprocess, 8.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Source\\IOT-dataanalysis-2025\\runs\\detect\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# coco8.yaml - YOLO í›ˆë ¨ì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ ì •ì˜ íŒŒì¼\n",
    "train_results = model.train(\n",
    "    data='./coco8.yaml', \n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    device='cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a2bc85",
   "metadata": {},
   "source": [
    "#### ì´ë¯¸ì§€ ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9fc3832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Source\\IOT-dataanalysis-2025\\day08\\0000001.jpg: 480x640 1 cat, 56.0ms\n",
      "Speed: 4.9ms preprocess, 56.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "result = model('./0000001.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f411d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maptplotlib ëª¨ë“ˆ ë¡œë“œ\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3322a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ ì´ë¯¸ì§€ ì €ìž¥\n",
    "img = result[0].plot()\n",
    "img_pil = Image.fromarray(img[..., ::-1])\n",
    "img_pil.save('./predict_result.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de42ac",
   "metadata": {},
   "source": [
    "### OpenCV\n",
    "- Opensource Computer Vision ì•½ìž. ì‹¤ì‹œê°„ ì»´í“¨í„° ë¹„ì „(ì‹œê°ì²˜ë¦¬)ì„ ëª©ì ìœ¼ë¡œ í”„ë¡œê·¸ëž˜ë° ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "- ì¸í…”ì—ì„œ 2000ë…„ì— C, C++ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ ê°œë°œ\n",
    "- íŒŒì´ì¬ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìžˆê²Œ ëž˜í•‘\n",
    "\n",
    "```shell\n",
    "> pip install opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86591dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from opencv-python) (1.24.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# OpenCV ì„¤ì¹˜\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5118b322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.11.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8014fe63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 640, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2 = cv2.imread('./predict_result.jpg')\n",
    "img2.shape # (464, 640, 3) -> (height, width, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12689a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœˆë„ìš° ì°½ ì˜¤í”ˆ\n",
    "cv2.imshow('predict result', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4febe4a",
   "metadata": {},
   "source": [
    "#### YOLO ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e367f0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 1 bottle, 1 cup, 1 bowl, 1 dining table, 1 tv, 1 mouse, 1 book, 106.3ms\n",
      "Speed: 5.5ms preprocess, 106.3ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./0000002.jpg')\n",
    "resized_img = cv2.resize(img, (640, 400))\n",
    "\n",
    "result = model(resized_img)\n",
    "plots = result[0].plot()\n",
    "\n",
    "cv2.imshow('predict_result', plots)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe33f36",
   "metadata": {},
   "source": [
    "#### ë™ì˜ìƒ í”Œë ˆì´\n",
    "- ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥\n",
    "- ë¼ì¦ˆë² ë¦¬íŒŒì´ ì›¹ìº  ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ\n",
    "video_path = './sample01.mp4'\n",
    "output_path = './sample01_output.mp4'\n",
    "count_path = './sample01_count.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56b92821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë™ì˜ìƒ í”Œë ˆì´\n",
    "cap = cv2.VideoCapture(video_path) # 0 -> ì›¹ìº ì´ë‚˜ ì¹´ë©”ë¼ ì„¤ì¹˜ëœ ë²ˆí˜¸\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    cv2.imshow('Video play', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # që²„íŠ¼ ëˆ„ë¥´ë©´\n",
    "        break\n",
    "\n",
    "cap.release() # ë¹„ë””ì˜¤ë¥¼ í•´ì œ\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024104f9",
   "metadata": {},
   "source": [
    "#### YOLO ì‹¤ì‹œê°„ ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d697fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°„ ëª¨ë“ˆ ë¡œë“œ\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e036201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 train, 1 clock, 73.0ms\n",
      "Speed: 2.8ms preprocess, 73.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 37.0ms\n",
      "Speed: 6.3ms preprocess, 37.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 37.3ms\n",
      "Speed: 2.8ms preprocess, 37.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 17.8ms\n",
      "Speed: 2.0ms preprocess, 17.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 12.1ms\n",
      "Speed: 1.4ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 11.9ms\n",
      "Speed: 1.5ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 11.8ms\n",
      "Speed: 1.8ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 12.7ms\n",
      "Speed: 1.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.1ms\n",
      "Speed: 1.6ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.5ms\n",
      "Speed: 1.3ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 13.8ms\n",
      "Speed: 2.2ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.8ms\n",
      "Speed: 1.3ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.3ms\n",
      "Speed: 1.4ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.2ms\n",
      "Speed: 1.9ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 12.5ms\n",
      "Speed: 2.1ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.7ms\n",
      "Speed: 1.3ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 13.4ms\n",
      "Speed: 1.4ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 13.8ms\n",
      "Speed: 1.7ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 12.7ms\n",
      "Speed: 1.4ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.7ms\n",
      "Speed: 1.6ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 13.3ms\n",
      "Speed: 1.6ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 12.3ms\n",
      "Speed: 1.5ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 13.0ms\n",
      "Speed: 1.4ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.1ms\n",
      "Speed: 1.4ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 10.8ms\n",
      "Speed: 1.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 1 clock, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.6ms\n",
      "Speed: 1.4ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.8ms\n",
      "Speed: 1.6ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 12.3ms\n",
      "Speed: 1.4ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.3ms\n",
      "Speed: 1.4ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.9ms\n",
      "Speed: 1.9ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 12.3ms\n",
      "Speed: 1.4ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 11.5ms\n",
      "Speed: 1.8ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 toilet, 13.1ms\n",
      "Speed: 1.7ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 13.8ms\n",
      "Speed: 2.6ms preprocess, 13.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 13.4ms\n",
      "Speed: 1.5ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.4ms\n",
      "Speed: 1.6ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.2ms\n",
      "Speed: 1.4ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.0ms\n",
      "Speed: 1.7ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 12.8ms\n",
      "Speed: 1.6ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 truck, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 truck, 10.3ms\n",
      "Speed: 1.4ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 11.3ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 10.9ms\n",
      "Speed: 1.6ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 10.9ms\n",
      "Speed: 1.6ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 traffic light, 1 clock, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 12.7ms\n",
      "Speed: 2.5ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 12.9ms\n",
      "Speed: 2.3ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 15.7ms\n",
      "Speed: 1.8ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 13.7ms\n",
      "Speed: 1.5ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 11.8ms\n",
      "Speed: 1.5ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 16.1ms\n",
      "Speed: 3.5ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 13.0ms\n",
      "Speed: 2.1ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 11.8ms\n",
      "Speed: 1.7ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 13.7ms\n",
      "Speed: 4.8ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 14.2ms\n",
      "Speed: 2.6ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 13.7ms\n",
      "Speed: 1.6ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 13.3ms\n",
      "Speed: 2.1ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 15.3ms\n",
      "Speed: 1.6ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 12.7ms\n",
      "Speed: 2.4ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 12.8ms\n",
      "Speed: 1.4ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 1 clock, 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 12.1ms\n",
      "Speed: 1.5ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 11.0ms\n",
      "Speed: 1.7ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 10.9ms\n",
      "Speed: 2.0ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 11.0ms\n",
      "Speed: 1.9ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 11.0ms\n",
      "Speed: 1.7ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 13.9ms\n",
      "Speed: 1.5ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 14.5ms\n",
      "Speed: 1.6ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 clock, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 14.5ms\n",
      "Speed: 1.7ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 clock, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 13.0ms\n",
      "Speed: 1.4ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 12.8ms\n",
      "Speed: 1.6ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 clock, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.9ms\n",
      "Speed: 1.6ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.8ms\n",
      "Speed: 1.5ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 12.4ms\n",
      "Speed: 1.8ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.1ms\n",
      "Speed: 1.6ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 12.7ms\n",
      "Speed: 1.8ms preprocess, 12.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.2ms\n",
      "Speed: 1.5ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 10.3ms\n",
      "Speed: 1.3ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.2ms\n",
      "Speed: 1.6ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 11.0ms\n",
      "Speed: 1.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.7ms\n",
      "Speed: 1.4ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 12.3ms\n",
      "Speed: 1.7ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.7ms\n",
      "Speed: 1.8ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.7ms\n",
      "Speed: 2.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 13.1ms\n",
      "Speed: 2.2ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 truck, 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 cell phone, 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 suitcase, 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.6ms\n",
      "Speed: 1.6ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 12.9ms\n",
      "Speed: 1.3ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.9ms\n",
      "Speed: 1.6ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 10.8ms\n",
      "Speed: 1.5ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 13.5ms\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 14.8ms\n",
      "Speed: 2.1ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.1ms\n",
      "Speed: 1.5ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 13.7ms\n",
      "Speed: 1.4ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.1ms\n",
      "Speed: 1.7ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 truck, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.8ms\n",
      "Speed: 1.5ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.9ms\n",
      "Speed: 1.5ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.7ms\n",
      "Speed: 1.5ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.8ms\n",
      "Speed: 1.5ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 clock, 10.7ms\n",
      "Speed: 1.3ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.4ms\n",
      "Speed: 1.3ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.1ms\n",
      "Speed: 1.6ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 13.6ms\n",
      "Speed: 1.5ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 10.6ms\n",
      "Speed: 1.3ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 10.5ms\n",
      "Speed: 1.3ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 10.5ms\n",
      "Speed: 1.3ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 13.2ms\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 13.5ms\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_path) \n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)     # ë™ì˜ìƒ FPS(Frame Per Second)\n",
    "frame_time = 1.0 / fps  # ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # 1280\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))    # 720\n",
    "\n",
    "# VideoWriter ê°ì²´ ìƒì„±(ë™ì˜ìƒ í™”ë©´ì— ê·¸ë¦¼, ê¸€ìžë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ ê°ì²´)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time() # ì‹œìž‘ ì‹œê°„ \n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    # ê°ì²´ íƒì§€\n",
    "    results = model(frame)\n",
    "    # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°\n",
    "    for result in results:\n",
    "        dectect_frame = result.plot()\n",
    "    # ê²°ê³¼ í”„ë ˆìž„ì„ íŒŒì¼ë¡œ ì €ìž¥\n",
    "    out.write(dectect_frame)\n",
    "    # ê²°ê³¼ í‘œì‹œ\n",
    "    cv2.imshow('YOLO Object Detection', dectect_frame)\n",
    "    cv2.imshow('Video play', frame)\n",
    "\n",
    "    # í”„ë ˆìž„ê°„ ì‹¤ì œ ì§€ì—°ì‹œê°„ ê³„ì‚°\n",
    "    elapsed_time = time.time() - start_time\n",
    "    delay = max(int((frame_time - elapsed_time) * 10000), 1)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # që²„íŠ¼ ëˆ„ë¥´ë©´\n",
    "        break\n",
    "\n",
    "cap.release() # ë¹„ë””ì˜¤ë¥¼ í•´ì œ\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca44d94",
   "metadata": {},
   "source": [
    "#### Car Counting\n",
    "- ì§€ì •ëœ ë¼ì¸ ì•„ëž˜ë¡œ ë‚´ë ¤ì˜¤ëŠ” ìžë™ì°¨ ê°œìˆ˜ ì¹´ìš´íŒ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ca0ad",
   "metadata": {},
   "source": [
    "- shapely ì„¤ì¹˜\n",
    "\n",
    "```shell\n",
    "> pip install shapely==2.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c59d1205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely==2.0.1\n",
      "  Downloading shapely-2.0.1-cp311-cp311-win_amd64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from shapely==2.0.1) (1.24.4)\n",
      "Downloading shapely-2.0.1-cp311-cp311-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 0.7/1.4 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 9.6 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely\n",
      "Successfully installed shapely-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install shapely==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fdc4582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lap\n",
      "  Downloading lap-0.5.12-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from lap) (1.24.4)\n",
      "Downloading lap-0.5.12-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 0.7/1.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 8.5 MB/s eta 0:00:00\n",
      "Installing collected packages: lap\n",
      "Successfully installed lap-0.5.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# lap ì„¤ì¹˜\n",
    "!pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54837a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics.solutions import ObjectCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e50be4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics Solutions:  {'region': [(20, 400), (1080, 400)], 'show_in': True, 'show_out': True, 'colormap': None, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'json_file': None, 'records': 5, 'show': True, 'model': 'yolo11n.pt'}\n",
      "\n",
      "0: 384x640 1 train, 74.4ms\n",
      "Speed: 2.7ms preprocess, 74.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 10.8ms\n",
      "Speed: 2.0ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 10.8ms\n",
      "Speed: 2.0ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 13.8ms\n",
      "Speed: 1.5ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 13.6ms\n",
      "Speed: 1.9ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.3ms\n",
      "Speed: 1.4ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.9ms\n",
      "Speed: 1.8ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 17.5ms\n",
      "Speed: 3.1ms preprocess, 17.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 21.4ms\n",
      "Speed: 2.5ms preprocess, 21.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 21.4ms\n",
      "Speed: 2.5ms preprocess, 21.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 21.1ms\n",
      "Speed: 3.1ms preprocess, 21.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 20.0ms\n",
      "Speed: 3.1ms preprocess, 20.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 21.1ms\n",
      "Speed: 2.4ms preprocess, 21.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 23.7ms\n",
      "Speed: 2.0ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 22.6ms\n",
      "Speed: 3.5ms preprocess, 22.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 20.2ms\n",
      "Speed: 2.4ms preprocess, 20.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 19.6ms\n",
      "Speed: 3.4ms preprocess, 19.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 21.9ms\n",
      "Speed: 2.6ms preprocess, 21.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 18.9ms\n",
      "Speed: 2.7ms preprocess, 18.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 4 cars, 19.7ms\n",
      "Speed: 2.7ms preprocess, 19.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 20.9ms\n",
      "Speed: 3.4ms preprocess, 20.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 24.3ms\n",
      "Speed: 3.9ms preprocess, 24.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 20.9ms\n",
      "Speed: 3.1ms preprocess, 20.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 20.2ms\n",
      "Speed: 2.2ms preprocess, 20.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 20.5ms\n",
      "Speed: 2.3ms preprocess, 20.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 21.5ms\n",
      "Speed: 4.6ms preprocess, 21.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 20.3ms\n",
      "Speed: 2.4ms preprocess, 20.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 20.5ms\n",
      "Speed: 2.7ms preprocess, 20.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 22.0ms\n",
      "Speed: 3.6ms preprocess, 22.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 25.6ms\n",
      "Speed: 2.2ms preprocess, 25.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 23.0ms\n",
      "Speed: 2.3ms preprocess, 23.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 24.8ms\n",
      "Speed: 2.2ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 23.3ms\n",
      "Speed: 4.7ms preprocess, 23.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 25.1ms\n",
      "Speed: 2.1ms preprocess, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 22.1ms\n",
      "Speed: 4.0ms preprocess, 22.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 26.6ms\n",
      "Speed: 6.0ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.4ms\n",
      "Speed: 1.6ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 13.1ms\n",
      "Speed: 2.5ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.5ms\n",
      "Speed: 2.1ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 2 trains, 16.2ms\n",
      "Speed: 1.7ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 12.4ms\n",
      "Speed: 2.0ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 16.2ms\n",
      "Speed: 2.6ms preprocess, 16.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 toilet, 10.4ms\n",
      "Speed: 1.6ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.3ms\n",
      "Speed: 1.6ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.0ms\n",
      "Speed: 1.9ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 13.8ms\n",
      "Speed: 1.7ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 12.7ms\n",
      "Speed: 2.5ms preprocess, 12.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.1ms\n",
      "Speed: 1.7ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 26.9ms\n",
      "Speed: 1.9ms preprocess, 26.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 22.4ms\n",
      "Speed: 1.8ms preprocess, 22.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 22.6ms\n",
      "Speed: 1.9ms preprocess, 22.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 20.6ms\n",
      "Speed: 2.2ms preprocess, 20.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 23.7ms\n",
      "Speed: 2.0ms preprocess, 23.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 20.8ms\n",
      "Speed: 2.2ms preprocess, 20.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 19.9ms\n",
      "Speed: 2.0ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 21.1ms\n",
      "Speed: 2.2ms preprocess, 21.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=4, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 4, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 22.8ms\n",
      "Speed: 1.8ms preprocess, 22.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=4, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 4, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 20.8ms\n",
      "Speed: 1.8ms preprocess, 20.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 21.2ms\n",
      "Speed: 1.7ms preprocess, 21.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 20.2ms\n",
      "Speed: 1.8ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 9.9ms\n",
      "Speed: 1.5ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 13.7ms\n",
      "Speed: 1.3ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 13.2ms\n",
      "Speed: 1.8ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 10.6ms\n",
      "Speed: 1.7ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 truck, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 13.7ms\n",
      "Speed: 1.5ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 traffic light, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.9ms\n",
      "Speed: 1.6ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.3ms\n",
      "Speed: 1.6ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.2ms\n",
      "Speed: 1.7ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 train, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 12.7ms\n",
      "Speed: 1.3ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 15.7ms\n",
      "Speed: 1.8ms preprocess, 15.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.8ms\n",
      "Speed: 2.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 21.9ms\n",
      "Speed: 2.1ms preprocess, 21.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 26.3ms\n",
      "Speed: 1.8ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 21.2ms\n",
      "Speed: 1.8ms preprocess, 21.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 20.0ms\n",
      "Speed: 1.9ms preprocess, 20.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 25.1ms\n",
      "Speed: 1.9ms preprocess, 25.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 18.9ms\n",
      "Speed: 1.8ms preprocess, 18.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.3ms\n",
      "Speed: 1.4ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.2ms\n",
      "Speed: 1.6ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 9.9ms\n",
      "Speed: 1.5ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 14.4ms\n",
      "Speed: 1.6ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.0ms\n",
      "Speed: 1.4ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.2ms\n",
      "Speed: 1.7ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 13.9ms\n",
      "Speed: 1.3ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 10.7ms\n",
      "Speed: 1.3ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 6 cars, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.4ms\n",
      "Speed: 1.3ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 8 cars, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 13.0ms\n",
      "Speed: 1.6ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 14.2ms\n",
      "Speed: 1.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 10.4ms\n",
      "Speed: 1.3ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 10.1ms\n",
      "Speed: 1.3ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 9.9ms\n",
      "Speed: 1.4ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.1ms\n",
      "Speed: 1.3ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.1ms\n",
      "Speed: 1.4ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 9 cars, 14.2ms\n",
      "Speed: 3.0ms preprocess, 14.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 23.1ms\n",
      "Speed: 2.9ms preprocess, 23.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 22.7ms\n",
      "Speed: 3.7ms preprocess, 22.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 27.2ms\n",
      "Speed: 1.8ms preprocess, 27.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 26.9ms\n",
      "Speed: 2.0ms preprocess, 26.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 28.5ms\n",
      "Speed: 1.9ms preprocess, 28.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 26.5ms\n",
      "Speed: 1.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 8 cars, 27.6ms\n",
      "Speed: 1.8ms preprocess, 27.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 20.4ms\n",
      "Speed: 4.3ms preprocess, 20.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 19.4ms\n",
      "Speed: 1.9ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 19.8ms\n",
      "Speed: 1.9ms preprocess, 19.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 10.4ms\n",
      "Speed: 1.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 10.7ms\n",
      "Speed: 1.7ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 14.2ms\n",
      "Speed: 1.3ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 13.7ms\n",
      "Speed: 1.5ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 suitcase, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.9ms\n",
      "Speed: 1.8ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.4ms\n",
      "Speed: 1.6ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 14.8ms\n",
      "Speed: 1.9ms preprocess, 14.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.7ms\n",
      "Speed: 1.3ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 10.2ms\n",
      "Speed: 1.6ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 10.4ms\n",
      "Speed: 1.5ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 11.6ms\n",
      "Speed: 1.8ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 14.8ms\n",
      "Speed: 1.6ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 13.3ms\n",
      "Speed: 3.1ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 13.3ms\n",
      "Speed: 1.3ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 6 cars, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 22.1ms\n",
      "Speed: 2.3ms preprocess, 22.1ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 21.0ms\n",
      "Speed: 1.8ms preprocess, 21.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 21.8ms\n",
      "Speed: 2.8ms preprocess, 21.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 22.1ms\n",
      "Speed: 1.7ms preprocess, 22.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.3ms\n",
      "Speed: 1.6ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 9.9ms\n",
      "Speed: 1.7ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 11.2ms\n",
      "Speed: 1.7ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 13.0ms\n",
      "Speed: 1.3ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 13.6ms\n",
      "Speed: 1.3ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 10.6ms\n",
      "Speed: 1.3ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 15.5ms\n",
      "Speed: 1.2ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.5ms\n",
      "Speed: 1.2ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 13.9ms\n",
      "Speed: 1.3ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 13.4ms\n",
      "Speed: 1.5ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), 'Error reading video file'\n",
    "\n",
    "region_points = [(20, 400), (1080, 400)]   # ë¼ì¸ìˆ˜\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)     # ë™ì˜ìƒ FPS(Frame Per Second)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # 1280\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))    # 720\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(count_path, fourcc, fps, (width, height))\n",
    "\n",
    "# ë¬¼ì²´ ì¹´ìš´í„° ì´ˆê¸°í™”\n",
    "counter = ObjectCounter(\n",
    "    show=True,  # ì²˜ë¦¬ë˜ëŠ” ë™ì•ˆ ë””ìŠ¤í”Œë ˆì´ ì—¬ë¶€\n",
    "    region=region_points,   # ì¹´ìš´íŒ…í•  ìœ„ì¹˜\n",
    "    model='yolo11n.pt',\n",
    ")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    results = counter(frame)\n",
    "    out.write(results.plot_im) # ì—¬ê¸° ì°¨ì´\n",
    "\n",
    "cap.release() # ë¹„ë””ì˜¤ë¥¼ í•´ì œ\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
